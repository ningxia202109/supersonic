langchain4j:
  # Replace `open_ai` with ollama/zhipu/azure/dashscope as needed.
  # Note:
  # 1. `open_ai` is commonly used to connect to cloud-based models;
  # 2. `ollama` is commonly used to connect to local models.
  open-ai:
    chat-model:
      # It is recommended to replace with your API key in production.
      # Note: The default API key `demo` is provided by langchain4j community
      #       which limits 1000 tokens per request.
      base-url: ${OPENAI_API_BASE:https://api.openai.com/v1}
      api-key: ${OPENAI_API_KEY:demo}
      model-name: ${OPENAI_MODEL_NAME:gpt-3.5-turbo}
      temperature: ${OPENAI_TEMPERATURE:0.0}
      timeout: ${OPENAI_TIMEOUT:PT60S}

  #    embedding-model:
  #      base-url: https://api.openai.com/v1
  #      api-key: demo
  #      model-name: text-embedding-3-small
  #      timeout: PT60S

  in-memory:
    embedding-model:
      model-name: bge-small-zh

#    embedding-store:
#      persist-path: /tmp

  chroma:
    embedding-store:
      baseUrl: http://${CHROMA_HOST}:8000
      timeout: 120s

#  milvus:
#    embedding-store:
#      host: localhost
#      port: 2379
#      uri: http://0.0.0.0:19530
#      token: demo
#      dimension: 512
#      timeout: 120s